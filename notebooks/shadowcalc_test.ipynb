{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Shadow calculation from LIDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import earthpy as et\n",
    "import earthpy.spatial as es\n",
    "import earthpy.plot as ep\n",
    "import rasterio as rio\n",
    "\n",
    "import zipfile\n",
    "from osgeo import gdal\n",
    "import requests\n",
    "import io\n",
    "from IPython.display import Image\n",
    "from ipyleaflet import Map, ImageOverlay\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pvlib\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOM: Digitales Oberflächen Modell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the first attempt at getting some data and casting shadows. Unfortunately since the DOM is one connected mesh, the shadow quality isn't great but it renders fast. We could use this raster as a placeholder to test the entire workflow.\n",
    "\n",
    "Link to the Berlin DOM data: https://fbinter.stadt-berlin.de/fb/berlin/service_intern.jsp?id=a_dom1@senstadt&type=FEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 4: `/home/unix_jz/github/shade-calculator/dev/shadowcalc/data/tile386_5818.xyz' not recognized as a supported file format.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received a NULL pointer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m path_to_save \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtile\u001b[39m\u001b[39m{\u001b[39;00mtile\u001b[39m}\u001b[39;00m\u001b[39m.xyz\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m f \u001b[39m=\u001b[39m download_file(link_to_tile, path_to_save)\n\u001b[0;32m---> 30\u001b[0m process_with_translate(f, \u001b[39m'\u001b[39;49m\u001b[39mEPSG:3857\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# replace 'output.tif' with your preferred output filename\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[44], line 16\u001b[0m, in \u001b[0;36mprocess_with_translate\u001b[0;34m(input_file, dst_srs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_with_translate\u001b[39m(input_file, dst_srs\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEPSG:4326\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     14\u001b[0m         \u001b[39m# 1. Convert to GeoTIFF\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         intermediate_tif \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mintermediate.tif\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# output from gdal_translate\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m         gdal\u001b[39m.\u001b[39;49mTranslate(intermediate_tif, input_file, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mGTiff\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     18\u001b[0m         \u001b[39m# Run GDALwarp to convert from EPSG:25833 projection to ESPG:4326\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         output_tif \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moutput.tif\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# output from gdalwarp\u001b[39;00m\n",
      "File \u001b[0;32m~/github/shade-calculator/venv/lib/python3.10/site-packages/osgeo/gdal.py:491\u001b[0m, in \u001b[0;36mTranslate\u001b[0;34m(destName, srcDS, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(srcDS, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    489\u001b[0m     srcDS \u001b[39m=\u001b[39m Open(srcDS)\n\u001b[0;32m--> 491\u001b[0m \u001b[39mreturn\u001b[39;00m TranslateInternal(destName, srcDS, opts, callback, callback_data)\n",
      "File \u001b[0;32m~/github/shade-calculator/venv/lib/python3.10/site-packages/osgeo/gdal.py:4674\u001b[0m, in \u001b[0;36mTranslateInternal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTranslateInternal\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[1;32m   4673\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"TranslateInternal(char const * dest, Dataset dataset, GDALTranslateOptions translateOptions, GDALProgressFunc callback=0, void * callback_data=None) -> Dataset\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4674\u001b[0m     \u001b[39mreturn\u001b[39;00m _gdal\u001b[39m.\u001b[39;49mTranslateInternal(\u001b[39m*\u001b[39;49margs)\n",
      "\u001b[0;31mValueError\u001b[0m: Received a NULL pointer."
     ]
    }
   ],
   "source": [
    "# Download a file\n",
    "def download_file(url, local_filename):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "    return local_filename\n",
    "\n",
    "tile = \"386_5818\"\n",
    "link_to_tile = f\"https://fbinter.stadt-berlin.de/fb/atom/DOM/DOM1_{tile}.zip\"\n",
    "\n",
    "def process_with_translate(input_file, dst_srs='EPSG:4326'):\n",
    "        # 1. Convert to GeoTIFF\n",
    "        intermediate_tif = \"intermediate.tif\"  # output from gdal_translate\n",
    "        gdal.Translate(intermediate_tif, input_file, format='GTiff')\n",
    "\n",
    "        # Run GDALwarp to convert from EPSG:25833 projection to ESPG:4326\n",
    "        output_tif = \"output.tif\"  # output from gdalwarp\n",
    "        gdal.Warp(output_tif, intermediate_tif, srcSRS='EPSG:25833', dstSRS=dst_srs)\n",
    "\n",
    "        # 3. Apply DEM processing\n",
    "        hillshade_tif = \"hillshade.tif\"  # output from DEMProcessing\n",
    "        ds = gdal.DEMProcessing(hillshade_tif, output_tif, 'hillshade')\n",
    "        gdal.DEMProcessing(\"\")\n",
    "        return ds\n",
    "\n",
    "path_to_save = os.path.join(os.getcwd(), \"data\", f\"tile{tile}.xyz\")\n",
    "f = download_file(link_to_tile, path_to_save)\n",
    "process_with_translate(f, 'EPSG:3857')  # replace 'output.tif' with your preferred output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 4: `/home/unix_jz/github/shade-calculator/dev/shadowcalc/data/tile386_5818.xyz' not recognized as a supported file format.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received a NULL pointer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m         gdal\u001b[39m.\u001b[39mDEMProcessing(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m         \u001b[39mreturn\u001b[39;00m ds\n\u001b[0;32m---> 16\u001b[0m process_with_translate(path_to_save, \u001b[39m'\u001b[39;49m\u001b[39mEPSG:3857\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# replace 'output.tif' with your preferred output filename\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m, in \u001b[0;36mprocess_with_translate\u001b[0;34m(input_file, dst_srs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_with_translate\u001b[39m(input_file, dst_srs\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEPSG:4326\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m         \u001b[39m# 1. Convert to GeoTIFF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m         intermediate_tif \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mintermediate.tif\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# output from gdal_translate\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m         gdal\u001b[39m.\u001b[39;49mTranslate(intermediate_tif, input_file, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mGTiff\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m         \u001b[39m# Run GDALwarp to convert from EPSG:25833 projection to ESPG:4326\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         output_tif \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moutput.tif\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# output from gdalwarp\u001b[39;00m\n",
      "File \u001b[0;32m~/github/shade-calculator/venv/lib/python3.10/site-packages/osgeo/gdal.py:491\u001b[0m, in \u001b[0;36mTranslate\u001b[0;34m(destName, srcDS, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(srcDS, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    489\u001b[0m     srcDS \u001b[39m=\u001b[39m Open(srcDS)\n\u001b[0;32m--> 491\u001b[0m \u001b[39mreturn\u001b[39;00m TranslateInternal(destName, srcDS, opts, callback, callback_data)\n",
      "File \u001b[0;32m~/github/shade-calculator/venv/lib/python3.10/site-packages/osgeo/gdal.py:4674\u001b[0m, in \u001b[0;36mTranslateInternal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTranslateInternal\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[1;32m   4673\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"TranslateInternal(char const * dest, Dataset dataset, GDALTranslateOptions translateOptions, GDALProgressFunc callback=0, void * callback_data=None) -> Dataset\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4674\u001b[0m     \u001b[39mreturn\u001b[39;00m _gdal\u001b[39m.\u001b[39;49mTranslateInternal(\u001b[39m*\u001b[39;49margs)\n",
      "\u001b[0;31mValueError\u001b[0m: Received a NULL pointer."
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/unix_jz/github/shade-calculator/dev/shadowcalc'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "data/hillshade.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_base.pyx:310\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_base.pyx:221\u001b[0m, in \u001b[0;36mrasterio._base.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:221\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: data/hillshade.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Open the file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhillshade.tif\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mwith\u001b[39;00m rio\u001b[39m.\u001b[39;49mopen(file_path) \u001b[39mas\u001b[39;00m ds:\n\u001b[1;32m      4\u001b[0m     img \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mread(\u001b[39m1\u001b[39m)  \u001b[39m# read the first (and only) band of the GeoTIFF\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# Create a new figure\u001b[39;00m\n",
      "File \u001b[0;32m~/github/shade-calculator/venv/lib/python3.10/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/github/shade-calculator/venv/lib/python3.10/site-packages/rasterio/__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m path \u001b[39m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     dataset \u001b[39m=\u001b[39m DatasetReader(path, driver\u001b[39m=\u001b[39;49mdriver, sharing\u001b[39m=\u001b[39;49msharing, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     dataset \u001b[39m=\u001b[39m get_writer_for_path(path, driver\u001b[39m=\u001b[39mdriver)(\n\u001b[1;32m    307\u001b[0m         path, mode, driver\u001b[39m=\u001b[39mdriver, sharing\u001b[39m=\u001b[39msharing, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:312\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: data/hillshade.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Open the file\n",
    "file_path = os.path.join('data', 'hillshade.tif')\n",
    "with rio.open(file_path) as ds:\n",
    "    img = ds.read(1)  # read the first (and only) band of the GeoTIFF\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlim([0, 400])\n",
    "plt.ylim([0, 400])\n",
    "# Display the image\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "# Optionally, add a colorbar\n",
    "plt.colorbar(label='Digital Elevation Model')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airborne Laserscanning (ALS) Segmented Data\n",
    "\n",
    "\n",
    "Direkter Download des Datensatzes (directly download the dataset)\n",
    "Airborne Laserscanning (ALS) Primäre 3D Laserscan-Daten - Download-Service - EPSG:25833 - las, gezippt.\n",
    "Erläuterung\tÜbersicht Downloadpakete, Flächenabdeckung je Datei 1 x 1 km\n",
    "- Mitte (37,3 GB)\thttps://fbinter.stadt-berlin.de/lidar//Mitte.zip\n",
    "- Nord (32,5 GB)\thttps://fbinter.stadt-berlin.de/lidar/Nord.zip\n",
    "- Nordost (1 GB)\thttps://fbinter.stadt-berlin.de/lidar/Nordost.zip\n",
    "- Nordwest (16,3 GB)\thttps://fbinter.stadt-berlin.de/lidar/Nordwest.zip\n",
    "- Ost (16,1 GB)\thttps://fbinter.stadt-berlin.de/lidar/Ost.zip\n",
    "- Süd (35,3 GB)\thttps://fbinter.stadt-berlin.de/lidar/Sued.zip\n",
    "- Südost (50 GB)\thttps://fbinter.stadt-berlin.de/lidar/Suedost.zip\n",
    "- Südwest (32 GB)\thttps://fbinter.stadt-berlin.de/lidar/Suedwest.zip\n",
    "- West (27,3 GB)\thttps://fbinter.stadt-berlin.de/lidar/West.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line to view Berlin Tiles:\n",
    "# Image(url='https://fbinter.stadt-berlin.de/fb/atom/DOP/Blattschnitt2x2km.gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSdata():\n",
    "    def __init__(self):\n",
    "        self.set_paths()\n",
    "        self.src_srs = \"EPSG:25833\"\n",
    "        \n",
    "    def set_paths(self):\n",
    "        \"\"\"Create a folder \n",
    "        in the same directory unless otherwise specified\n",
    "        \"\"\"\n",
    "        self.data_path = os.path.join(os.getcwd(), \"data\")\n",
    "        #file_path = os.path.join(data_path, f'temp_{filename}.xyz')\n",
    "\n",
    "    def request_data_from_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        assert response.status_code == 200\n",
    "        self.response = response\n",
    "\n",
    "\n",
    "    def download_file(self, url):\n",
    "        self.local_filename = os.path.join(self.data_path, url.split(\"/\")[-1])\n",
    "\n",
    "        response = requests.get(url, stream=True)\n",
    "\n",
    "        file_size = int(response.headers.get('Content-Length', 0))\n",
    "        progress = tqdm(response.iter_content(1024), f'Downloading {self.local_filename}', total=file_size, unit='B', unit_scale=True, unit_divisor=1024)\n",
    "\n",
    "        with open(self.local_filename, 'wb') as f:\n",
    "            for data in progress.iterable:\n",
    "                f.write(data)\n",
    "                progress.update(len(data))\n",
    "\n",
    "\n",
    "    def write_als_locally(self):\n",
    "        with zipfile.ZipFile(self.local_filename, 'r') as zip_ref:\n",
    "            for member in tqdm(zip_ref.infolist(), desc='Extracting '):\n",
    "                zip_ref.extract(member, self.data_path)\n",
    "        print(f\"Extracted all files to directory: {os.path.abspath(self.data_path)}\")\n",
    "\n",
    "\n",
    "    def write_single_file_locally(self):\n",
    "        with zipfile.ZipFile(response, 'r') as zip_ref:\n",
    "            zip_ref.extractall(self.data_path)\n",
    "        print(f\"Extracted all files to directory: {os.path.abspath(self.data_path)}\")\n",
    "\n",
    "\n",
    "    def write_zip_locally(self, zip_file):\n",
    "        unzip_path = os.path.join(self.data_path, zip_file[:-4])\n",
    "        with zipfile.ZipFile(zip_file, \"r\") as z:\n",
    "            for filename in z.namelist():\n",
    "                # Open each file\n",
    "                with z.open(filename) as f:\n",
    "                    file_path = os.path.join(unzip_path, filename)\n",
    "                    # Check if the file is a raster file by checking the extension\n",
    "                    with open(file_path, 'wb') as temp_file:\n",
    "                        temp_file.write(f.read())\n",
    "    \n",
    "    def process_with_translate(self, input_file, dst_srs='EPSG:4326'):\n",
    "        # 1. Convert to GeoTIFF\n",
    "        intermediate_tif = \"intermediate.tif\"  # output from gdal_translate\n",
    "        gdal.Translate(intermediate_tif, input_file, format='GTiff')\n",
    "\n",
    "        # Run GDALwarp to convert from EPSG:25833 projection to ESPG:4326\n",
    "        output_tif = \"output.tif\"  # output from gdalwarp\n",
    "        gdal.Warp(output_tif, intermediate_tif, srcSRS='EPSG:25833', dstSRS=dst_srs)\n",
    "\n",
    "        # 3. Apply DEM processing\n",
    "        hillshade_tif = \"hillshade.tif\"  # output from DEMProcessing\n",
    "        ds = gdal.DEMProcessing(hillshade_tif, output_tif, 'hillshade')\n",
    "        gdal.DEMProcessing(\"\")\n",
    "        return ds\n",
    "        # Process the XYZ file with Translate\n",
    "        #process_with_translate(file_path, 'EPSG:3857')  # replace 'output.tif' with your preferred output filename\n",
    "\n",
    "    def process_superseded(self, r):\n",
    "        #data_path = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), \"data\")\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        for filename in z.namelist():\n",
    "            file_path = os.path.join('data', f'temp_{filename}.xyz')\n",
    "            print(filename)\n",
    "            # Open each file\n",
    "            with z.open(filename) as f:\n",
    "                # Check if the file is a raster file by checking the extension\n",
    "                with open(self.data_path, 'wb') as temp_file:\n",
    "                    temp_file.write(f.read())\n",
    "                # Process the XYZ file with Translate\n",
    "                    #process_with_translate(file_path, 'EPSG:3857')  # replace 'output.tif' with your preferred output filename\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "That compression method is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m nord_ost \u001b[39m=\u001b[39m ALSdata()\n\u001b[1;32m      2\u001b[0m \u001b[39m#nord_ost.download_file(nordost)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m nord_ost\u001b[39m.\u001b[39;49mwrite_zip_locally(\u001b[39m\"\u001b[39;49m\u001b[39m/home/unix_jz/github/shade-calculator/dev/shadowcalc/data/Nordost.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m nord_ost\u001b[39m.\u001b[39mwrite_als_locally()\n",
      "Cell \u001b[0;32mIn[11], line 51\u001b[0m, in \u001b[0;36mALSdata.write_zip_locally\u001b[0;34m(self, zip_file)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(zip_file, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m z:\n\u001b[1;32m     49\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m z\u001b[39m.\u001b[39mnamelist():\n\u001b[1;32m     50\u001b[0m         \u001b[39m# Open each file\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m         \u001b[39mwith\u001b[39;00m z\u001b[39m.\u001b[39;49mopen(filename) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     52\u001b[0m             file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(unzip_path, filename)\n\u001b[1;32m     53\u001b[0m             \u001b[39m# Check if the file is a raster file by checking the extension\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/zipfile.py:1571\u001b[0m, in \u001b[0;36mZipFile.open\u001b[0;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1569\u001b[0m         pwd \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[39mreturn\u001b[39;00m ZipExtFile(zef_file, mode, zinfo, pwd, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1572\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m   1573\u001b[0m     zef_file\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/zipfile.py:800\u001b[0m, in \u001b[0;36mZipExtFile.__init__\u001b[0;34m(self, fileobj, mode, zipinfo, pwd, close_fileobj)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m=\u001b[39m zipinfo\u001b[39m.\u001b[39mcompress_size\n\u001b[1;32m    798\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_left \u001b[39m=\u001b[39m zipinfo\u001b[39m.\u001b[39mfile_size\n\u001b[0;32m--> 800\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor \u001b[39m=\u001b[39m _get_decompressor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compress_type)\n\u001b[1;32m    802\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/zipfile.py:699\u001b[0m, in \u001b[0;36m_get_decompressor\u001b[0;34m(compress_type)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_decompressor\u001b[39m(compress_type):\n\u001b[0;32m--> 699\u001b[0m     _check_compression(compress_type)\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m compress_type \u001b[39m==\u001b[39m ZIP_STORED:\n\u001b[1;32m    701\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/zipfile.py:679\u001b[0m, in \u001b[0;36m_check_compression\u001b[0;34m(compression)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    677\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCompression requires the (missing) lzma module\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    678\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThat compression method is not supported\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: That compression method is not supported"
     ]
    }
   ],
   "source": [
    "nord_ost = ALSdata()\n",
    "#nord_ost.download_file(nordost)\n",
    "nord_ost.write_zip_locally(\"/home/unix_jz/github/shade-calculator/dev/shadowcalc/data/Nordost.zip\")\n",
    "\n",
    "nord_ost.write_als_locally()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sun Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     elevation  apparent_zenith\n",
      "2023-06-16 03:00:00   1.130931        88.520479\n",
      "2023-06-16 04:00:00   8.793579        81.105593\n",
      "2023-06-16 05:00:00  17.277196        72.669858\n",
      "2023-06-16 06:00:00  26.249403        63.716746\n",
      "2023-06-16 07:00:00  35.368432        54.607934\n",
      "2023-06-16 08:00:00  44.214851        45.767870\n",
      "2023-06-16 09:00:00  52.163359        37.823573\n",
      "2023-06-16 10:00:00  58.187037        31.802524\n",
      "2023-06-16 11:00:00  60.843918        29.146694\n",
      "2023-06-16 12:00:00  59.174202        30.815756\n",
      "2023-06-16 13:00:00  53.810501        36.177189\n",
      "2023-06-16 14:00:00  46.206243        43.777634\n",
      "2023-06-16 15:00:00  37.505666        52.472461\n",
      "2023-06-16 16:00:00  28.410265        61.558825\n",
      "2023-06-16 17:00:00  19.373718        70.579228\n",
      "2023-06-16 18:00:00  10.748329        79.167666\n",
      "2023-06-16 19:00:00   2.864723        86.902233\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "latitude, longitude = 52.47, 13.4 # New York City\n",
    "time = pd.date_range('2023-06-16 00:00:00', '2023-06-16 23:59:59', freq='H')  # One day with hourly frequency\n",
    "\n",
    "# Create location object\n",
    "location = pvlib.location.Location(latitude, longitude)\n",
    "\n",
    "# Calculate solar position\n",
    "solar_position = location.get_solarposition(time)\n",
    "solar_position = solar_position.loc[solar_position[\"elevation\"]>0,:]\n",
    "# Print solar azimuth and zenith\n",
    "print(solar_position[[\"elevation\", \"apparent_zenith\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
